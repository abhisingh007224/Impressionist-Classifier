{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":25,"outputs":[{"output_type":"stream","text":"/kaggle/working/__notebook_source__.ipynb\n/kaggle/working/work/testing/Degas/213309.jpg\n/kaggle/working/work/testing/Degas/213454.jpg\n/kaggle/working/work/testing/Degas/213756.jpg\n/kaggle/working/work/testing/Degas/213388.jpg\n/kaggle/working/work/testing/Degas/213312.jpg\n/kaggle/working/work/testing/Degas/213263.jpg\n/kaggle/working/work/testing/Degas/213493.jpg\n/kaggle/working/work/testing/Degas/213278.jpg\n/kaggle/working/work/testing/Degas/213641.jpg\n/kaggle/working/work/testing/Degas/213738.jpg\n/kaggle/working/work/testing/Degas/213579.jpg\n/kaggle/working/work/testing/Degas/213648.jpg\n/kaggle/working/work/testing/Degas/213616.jpg\n/kaggle/working/work/testing/Degas/213742.jpg\n/kaggle/working/work/testing/Degas/213593.jpg\n/kaggle/working/work/testing/Degas/213513.jpg\n/kaggle/working/work/testing/Degas/213675.jpg\n/kaggle/working/work/testing/Degas/213555.jpg\n/kaggle/working/work/testing/Degas/213685.jpg\n/kaggle/working/work/testing/Degas/213581.jpg\n/kaggle/working/work/testing/Degas/213447.jpg\n/kaggle/working/work/testing/Degas/213362.jpg\n/kaggle/working/work/testing/Degas/213283.jpg\n/kaggle/working/work/testing/Degas/213715.jpg\n/kaggle/working/work/testing/Degas/213281.jpg\n/kaggle/working/work/testing/Degas/213319.jpg\n/kaggle/working/work/testing/Degas/213761.jpg\n/kaggle/working/work/testing/Degas/213596.jpg\n/kaggle/working/work/testing/Degas/213419.jpg\n/kaggle/working/work/testing/Degas/213317.jpg\n/kaggle/working/work/testing/Degas/213387.jpg\n/kaggle/working/work/testing/Degas/213621.jpg\n/kaggle/working/work/testing/Degas/213315.jpg\n/kaggle/working/work/testing/Degas/213736.jpg\n/kaggle/working/work/testing/Degas/213390.jpg\n/kaggle/working/work/testing/Degas/213615.jpg\n/kaggle/working/work/testing/Degas/213410.jpg\n/kaggle/working/work/testing/Degas/213489.jpg\n/kaggle/working/work/testing/Degas/213466.jpg\n/kaggle/working/work/testing/Degas/213393.jpg\n/kaggle/working/work/testing/Degas/213613.jpg\n/kaggle/working/work/testing/Degas/213719.jpg\n/kaggle/working/work/testing/Degas/213666.jpg\n/kaggle/working/work/testing/Degas/213436.jpg\n/kaggle/working/work/testing/Degas/213297.jpg\n/kaggle/working/work/testing/Degas/213694.jpg\n/kaggle/working/work/testing/Degas/213699.jpg\n/kaggle/working/work/testing/Degas/213285.jpg\n/kaggle/working/work/testing/Degas/213741.jpg\n/kaggle/working/work/testing/Degas/213479.jpg\n/kaggle/working/work/testing/Degas/213650.jpg\n/kaggle/working/work/testing/Degas/213471.jpg\n/kaggle/working/work/testing/Degas/213355.jpg\n/kaggle/working/work/testing/Degas/213271.jpg\n/kaggle/working/work/testing/Degas/213765.jpg\n/kaggle/working/work/testing/Degas/213295.jpg\n/kaggle/working/work/testing/Degas/213449.jpg\n/kaggle/working/work/testing/Degas/213534.jpg\n/kaggle/working/work/testing/Degas/213484.jpg\n/kaggle/working/work/testing/Degas/213762.jpg\n/kaggle/working/work/testing/Degas/213713.jpg\n/kaggle/working/work/testing/Degas/213300.jpg\n/kaggle/working/work/testing/Degas/213324.jpg\n/kaggle/working/work/testing/Degas/213352.jpg\n/kaggle/working/work/testing/Degas/213494.jpg\n/kaggle/working/work/testing/Degas/213656.jpg\n/kaggle/working/work/testing/Degas/213402.jpg\n/kaggle/working/work/testing/Degas/213401.jpg\n/kaggle/working/work/testing/Degas/213409.jpg\n/kaggle/working/work/testing/Degas/213354.jpg\n/kaggle/working/work/testing/Degas/213481.jpg\n/kaggle/working/work/testing/Degas/213519.jpg\n/kaggle/working/work/testing/Hassam/244306.jpg\n/kaggle/working/work/testing/Hassam/244108.jpg\n/kaggle/working/work/testing/Hassam/244104.jpg\n/kaggle/working/work/testing/Hassam/244053.jpg\n/kaggle/working/work/testing/Hassam/244081.jpg\n/kaggle/working/work/testing/Hassam/244069.jpg\n/kaggle/working/work/testing/Hassam/244291.jpg\n/kaggle/working/work/testing/Hassam/244211.jpg\n/kaggle/working/work/testing/Hassam/244221.jpg\n/kaggle/working/work/testing/Hassam/244296.jpg\n/kaggle/working/work/testing/Hassam/244041.jpg\n/kaggle/working/work/testing/Hassam/244216.jpg\n/kaggle/working/work/testing/Hassam/244044.jpg\n/kaggle/working/work/testing/Hassam/244088.jpg\n/kaggle/working/work/testing/Hassam/243872.jpg\n/kaggle/working/work/testing/Hassam/244243.jpg\n/kaggle/working/work/testing/Hassam/244295.jpg\n/kaggle/working/work/testing/Hassam/243857.jpg\n/kaggle/working/work/testing/Hassam/244158.jpg\n/kaggle/working/work/testing/Hassam/243860.jpg\n/kaggle/working/work/testing/Hassam/244107.jpg\n/kaggle/working/work/testing/Hassam/243868.jpg\n/kaggle/working/work/testing/Hassam/243889.jpg\n/kaggle/working/work/testing/Hassam/243962.jpg\n/kaggle/working/work/testing/Hassam/243941.jpg\n/kaggle/working/work/testing/Hassam/244269.jpg\n/kaggle/working/work/testing/Hassam/244273.jpg\n/kaggle/working/work/testing/Hassam/244271.jpg\n/kaggle/working/work/testing/Hassam/244070.jpg\n/kaggle/working/work/testing/Hassam/243983.jpg\n/kaggle/working/work/testing/Hassam/244037.jpg\n/kaggle/working/work/testing/Hassam/244253.jpg\n/kaggle/working/work/testing/Hassam/244066.jpg\n/kaggle/working/work/testing/Hassam/244189.jpg\n/kaggle/working/work/testing/Hassam/243976.jpg\n/kaggle/working/work/testing/Hassam/244060.jpg\n/kaggle/working/work/testing/Hassam/244100.jpg\n/kaggle/working/work/testing/Hassam/244123.jpg\n/kaggle/working/work/testing/Hassam/244233.jpg\n/kaggle/working/work/testing/Hassam/243963.jpg\n/kaggle/working/work/testing/Hassam/243906.jpg\n/kaggle/working/work/testing/Hassam/244025.jpg\n/kaggle/working/work/testing/Hassam/244020.jpg\n/kaggle/working/work/testing/Hassam/243856.jpg\n/kaggle/working/work/testing/Hassam/243878.jpg\n/kaggle/working/work/testing/Hassam/243898.jpg\n/kaggle/working/work/testing/Hassam/243995.jpg\n/kaggle/working/work/testing/Hassam/244091.jpg\n/kaggle/working/work/testing/Hassam/243884.jpg\n/kaggle/working/work/testing/Hassam/244128.jpg\n/kaggle/working/work/testing/Hassam/244200.jpg\n/kaggle/working/work/testing/Hassam/244099.jpg\n/kaggle/working/work/testing/Hassam/243991.jpg\n/kaggle/working/work/testing/Hassam/243887.jpg\n/kaggle/working/work/testing/Hassam/243917.jpg\n/kaggle/working/work/testing/Hassam/244110.jpg\n/kaggle/working/work/testing/Hassam/244130.jpg\n/kaggle/working/work/testing/Hassam/244005.jpg\n/kaggle/working/work/testing/Hassam/244058.jpg\n/kaggle/working/work/testing/Hassam/244259.jpg\n/kaggle/working/work/testing/Hassam/244227.jpg\n/kaggle/working/work/testing/Hassam/243880.jpg\n/kaggle/working/work/testing/Hassam/244137.jpg\n/kaggle/working/work/testing/Hassam/244204.jpg\n/kaggle/working/work/testing/Hassam/244197.jpg\n/kaggle/working/work/testing/Hassam/243933.jpg\n/kaggle/working/work/testing/Hassam/244127.jpg\n/kaggle/working/work/testing/Hassam/243986.jpg\n/kaggle/working/work/testing/Hassam/244027.jpg\n/kaggle/working/work/testing/Hassam/244268.jpg\n/kaggle/working/work/testing/Hassam/243978.jpg\n/kaggle/working/work/testing/Hassam/243918.jpg\n/kaggle/working/work/testing/Cezanne/215669.jpg\n/kaggle/working/work/testing/Cezanne/215561.jpg\n/kaggle/working/work/testing/Cezanne/215754.jpg\n/kaggle/working/work/testing/Cezanne/215717.jpg\n/kaggle/working/work/testing/Cezanne/215529.jpg\n/kaggle/working/work/testing/Cezanne/215713.jpg\n/kaggle/working/work/testing/Cezanne/215779.jpg\n/kaggle/working/work/testing/Cezanne/215725.jpg\n/kaggle/working/work/testing/Cezanne/215599.jpg\n/kaggle/working/work/testing/Cezanne/215640.jpg\n/kaggle/working/work/testing/Cezanne/215836.jpg\n/kaggle/working/work/testing/Cezanne/215687.jpg\n/kaggle/working/work/testing/Cezanne/215714.jpg\n/kaggle/working/work/testing/Cezanne/215555.jpg\n/kaggle/working/work/testing/Cezanne/215623.jpg\n/kaggle/working/work/testing/Cezanne/215532.jpg\n/kaggle/working/work/testing/Cezanne/215637.jpg\n/kaggle/working/work/testing/Cezanne/215813.jpg\n/kaggle/working/work/testing/Cezanne/215697.jpg\n/kaggle/working/work/testing/Cezanne/215512.jpg\n/kaggle/working/work/testing/Cezanne/215786.jpg\n/kaggle/working/work/testing/Cezanne/215773.jpg\n/kaggle/working/work/testing/Cezanne/215806.jpg\n/kaggle/working/work/testing/Cezanne/215592.jpg\n/kaggle/working/work/testing/Cezanne/215774.jpg\n/kaggle/working/work/testing/Cezanne/215686.jpg\n/kaggle/working/work/testing/Cezanne/215846.jpg\n/kaggle/working/work/testing/Cezanne/215649.jpg\n/kaggle/working/work/testing/Cezanne/215505.jpg\n/kaggle/working/work/testing/Cezanne/215756.jpg\n/kaggle/working/work/testing/Cezanne/215495.jpg\n/kaggle/working/work/testing/Cezanne/215569.jpg\n/kaggle/working/work/testing/Cezanne/215727.jpg\n/kaggle/working/work/testing/Cezanne/215704.jpg\n/kaggle/working/work/testing/Cezanne/215506.jpg\n/kaggle/working/work/testing/Cezanne/215533.jpg\n/kaggle/working/work/testing/Cezanne/215580.jpg\n/kaggle/working/work/testing/Cezanne/215796.jpg\n/kaggle/working/work/testing/Cezanne/215810.jpg\n/kaggle/working/work/testing/Cezanne/215521.jpg\n/kaggle/working/work/testing/Cezanne/215537.jpg\n/kaggle/working/work/testing/Cezanne/215593.jpg\n/kaggle/working/work/testing/Cezanne/215789.jpg\n/kaggle/working/work/testing/Cezanne/215513.jpg\n/kaggle/working/work/testing/Cezanne/215587.jpg\n/kaggle/working/work/testing/Cezanne/215776.jpg\n/kaggle/working/work/testing/Cezanne/215610.jpg\n/kaggle/working/work/testing/Cezanne/215606.jpg\n/kaggle/working/work/testing/Cezanne/215558.jpg\n/kaggle/working/work/testing/Cezanne/215821.jpg\n/kaggle/working/work/testing/Cezanne/215726.jpg\n/kaggle/working/work/testing/Cezanne/215804.jpg\n/kaggle/working/work/testing/Cezanne/215742.jpg\n/kaggle/working/work/testing/Cezanne/215822.jpg\n/kaggle/working/work/testing/Cezanne/215502.jpg\n/kaggle/working/work/testing/Cezanne/215718.jpg\n/kaggle/working/work/testing/Cezanne/215811.jpg\n/kaggle/working/work/testing/Cezanne/215498.jpg\n/kaggle/working/work/testing/Cezanne/215712.jpg\n/kaggle/working/work/testing/Cezanne/215550.jpg\n/kaggle/working/work/testing/Cezanne/215557.jpg\n/kaggle/working/work/testing/Cezanne/215694.jpg\n/kaggle/working/work/testing/Cezanne/215723.jpg\n/kaggle/working/work/testing/Cezanne/215508.jpg\n/kaggle/working/work/testing/Cezanne/215752.jpg\n/kaggle/working/work/testing/Cezanne/215667.jpg\n/kaggle/working/work/testing/Cezanne/215817.jpg\n/kaggle/working/work/testing/Cezanne/215638.jpg\n/kaggle/working/work/testing/Cezanne/215632.jpg\n/kaggle/working/work/testing/Cezanne/215828.jpg\n/kaggle/working/work/testing/Cezanne/215562.jpg\n/kaggle/working/work/testing/Cezanne/215715.jpg\n/kaggle/working/work/testing/Renoir/218213.jpg\n/kaggle/working/work/testing/Renoir/218373.jpg\n/kaggle/working/work/testing/Renoir/219022.jpg\n/kaggle/working/work/testing/Renoir/218912.jpg\n/kaggle/working/work/testing/Renoir/218411.jpg\n/kaggle/working/work/testing/Renoir/218859.jpg\n/kaggle/working/work/testing/Renoir/218366.jpg\n/kaggle/working/work/testing/Renoir/218209.jpg\n/kaggle/working/work/testing/Renoir/218922.jpg\n/kaggle/working/work/testing/Renoir/218334.jpg\n/kaggle/working/work/testing/Renoir/218513.jpg\n/kaggle/working/work/testing/Renoir/218666.jpg\n/kaggle/working/work/testing/Renoir/218532.jpg\n/kaggle/working/work/testing/Renoir/219082.jpg\n/kaggle/working/work/testing/Renoir/218265.jpg\n/kaggle/working/work/testing/Renoir/219171.jpg\n/kaggle/working/work/testing/Renoir/218272.jpg\n/kaggle/working/work/testing/Renoir/218242.jpg\n/kaggle/working/work/testing/Renoir/218758.jpg\n/kaggle/working/work/testing/Renoir/218364.jpg\n/kaggle/working/work/testing/Renoir/218872.jpg\n/kaggle/working/work/testing/Renoir/218562.jpg\n/kaggle/working/work/testing/Renoir/218302.jpg\n/kaggle/working/work/testing/Renoir/218958.jpg\n/kaggle/working/work/testing/Renoir/218429.jpg\n/kaggle/working/work/testing/Renoir/218323.jpg\n/kaggle/working/work/testing/Renoir/218283.jpg\n/kaggle/working/work/testing/Renoir/218826.jpg\n/kaggle/working/work/testing/Renoir/218380.jpg\n/kaggle/working/work/testing/Renoir/218640.jpg\n/kaggle/working/work/testing/Renoir/218661.jpg\n/kaggle/working/work/testing/Renoir/218232.jpg\n/kaggle/working/work/testing/Renoir/218311.jpg\n/kaggle/working/work/testing/Renoir/218275.jpg\n/kaggle/working/work/testing/Renoir/219046.jpg\n/kaggle/working/work/testing/Renoir/218728.jpg\n/kaggle/working/work/testing/Renoir/218410.jpg\n/kaggle/working/work/testing/Renoir/218937.jpg\n/kaggle/working/work/testing/Renoir/218337.jpg\n/kaggle/working/work/testing/Renoir/218921.jpg\n/kaggle/working/work/testing/Renoir/218634.jpg\n/kaggle/working/work/testing/Renoir/218642.jpg\n/kaggle/working/work/testing/Renoir/218483.jpg\n/kaggle/working/work/testing/Renoir/219011.jpg\n/kaggle/working/work/testing/Renoir/218416.jpg\n/kaggle/working/work/testing/Renoir/218459.jpg\n/kaggle/working/work/testing/Renoir/218169.jpg\n/kaggle/working/work/testing/Renoir/218448.jpg\n/kaggle/working/work/testing/Renoir/218446.jpg\n/kaggle/working/work/testing/Renoir/218901.jpg\n/kaggle/working/work/testing/Renoir/219023.jpg\n/kaggle/working/work/testing/Renoir/218453.jpg\n/kaggle/working/work/testing/Renoir/218883.jpg\n/kaggle/working/work/testing/Renoir/218224.jpg\n/kaggle/working/work/testing/Renoir/218450.jpg\n/kaggle/working/work/testing/Renoir/218291.jpg\n/kaggle/working/work/testing/Renoir/218692.jpg\n/kaggle/working/work/testing/Renoir/218985.jpg\n/kaggle/working/work/testing/Renoir/218392.jpg\n/kaggle/working/work/testing/Renoir/218424.jpg\n/kaggle/working/work/testing/Renoir/218387.jpg\n/kaggle/working/work/testing/Renoir/218865.jpg\n/kaggle/working/work/testing/Renoir/218188.jpg\n/kaggle/working/work/testing/Renoir/219084.jpg\n/kaggle/working/work/testing/Renoir/218494.jpg\n/kaggle/working/work/testing/Renoir/218716.jpg\n/kaggle/working/work/testing/Renoir/218552.jpg\n/kaggle/working/work/testing/Renoir/219001.jpg\n/kaggle/working/work/testing/Renoir/218651.jpg\n/kaggle/working/work/testing/Renoir/218964.jpg\n/kaggle/working/work/testing/Renoir/218965.jpg\n/kaggle/working/work/testing/Renoir/219074.jpg\n/kaggle/working/work/testing/Pissarro/208044.jpg\n/kaggle/working/work/testing/Pissarro/208636.jpg\n/kaggle/working/work/testing/Pissarro/208306.jpg\n/kaggle/working/work/testing/Pissarro/208395.jpg\n/kaggle/working/work/testing/Pissarro/208511.jpg\n/kaggle/working/work/testing/Pissarro/208182.jpg\n/kaggle/working/work/testing/Pissarro/208375.jpg\n/kaggle/working/work/testing/Pissarro/208071.jpg\n/kaggle/working/work/testing/Pissarro/208584.jpg\n/kaggle/working/work/testing/Pissarro/208597.jpg\n/kaggle/working/work/testing/Pissarro/208474.jpg\n/kaggle/working/work/testing/Pissarro/208665.jpg\n/kaggle/working/work/testing/Pissarro/208566.jpg\n/kaggle/working/work/testing/Pissarro/208638.jpg\n/kaggle/working/work/testing/Pissarro/208447.jpg\n/kaggle/working/work/testing/Pissarro/208592.jpg\n/kaggle/working/work/testing/Pissarro/208346.jpg\n/kaggle/working/work/testing/Pissarro/208528.jpg\n/kaggle/working/work/testing/Pissarro/208254.jpg\n/kaggle/working/work/testing/Pissarro/208555.jpg\n/kaggle/working/work/testing/Pissarro/208183.jpg\n/kaggle/working/work/testing/Pissarro/208602.jpg\n/kaggle/working/work/testing/Pissarro/208235.jpg\n/kaggle/working/work/testing/Pissarro/208060.jpg\n/kaggle/working/work/testing/Pissarro/208613.jpg\n/kaggle/working/work/testing/Pissarro/208629.jpg\n/kaggle/working/work/testing/Pissarro/208446.jpg\n/kaggle/working/work/testing/Pissarro/208223.jpg\n/kaggle/working/work/testing/Pissarro/208529.jpg\n/kaggle/working/work/testing/Pissarro/208184.jpg\n/kaggle/working/work/testing/Pissarro/208410.jpg\n/kaggle/working/work/testing/Pissarro/208417.jpg\n/kaggle/working/work/testing/Pissarro/208408.jpg\n/kaggle/working/work/testing/Pissarro/208142.jpg\n/kaggle/working/work/testing/Pissarro/208567.jpg\n/kaggle/working/work/testing/Pissarro/208711.jpg\n/kaggle/working/work/testing/Pissarro/208322.jpg\n/kaggle/working/work/testing/Pissarro/208666.jpg\n/kaggle/working/work/testing/Pissarro/208156.jpg\n/kaggle/working/work/testing/Pissarro/208577.jpg\n/kaggle/working/work/testing/Pissarro/208092.jpg\n/kaggle/working/work/testing/Pissarro/208381.jpg\n/kaggle/working/work/testing/Pissarro/208204.jpg\n/kaggle/working/work/testing/Pissarro/208530.jpg\n/kaggle/working/work/testing/Pissarro/208155.jpg\n/kaggle/working/work/testing/Pissarro/208253.jpg\n/kaggle/working/work/testing/Pissarro/208521.jpg\n/kaggle/working/work/testing/Pissarro/208380.jpg\n/kaggle/working/work/testing/Pissarro/208110.jpg\n/kaggle/working/work/testing/Pissarro/208101.jpg\n/kaggle/working/work/testing/Pissarro/208116.jpg\n/kaggle/working/work/testing/Pissarro/208397.jpg\n/kaggle/working/work/testing/Pissarro/208489.jpg\n/kaggle/working/work/testing/Pissarro/208558.jpg\n/kaggle/working/work/testing/Pissarro/208173.jpg\n/kaggle/working/work/testing/Pissarro/208052.jpg\n/kaggle/working/work/testing/Pissarro/208437.jpg\n/kaggle/working/work/testing/Pissarro/208672.jpg\n/kaggle/working/work/testing/Pissarro/208281.jpg\n/kaggle/working/work/testing/Pissarro/208100.jpg\n/kaggle/working/work/testing/Pissarro/208419.jpg\n/kaggle/working/work/testing/Pissarro/208556.jpg\n/kaggle/working/work/testing/Pissarro/208436.jpg\n/kaggle/working/work/testing/Pissarro/208484.jpg\n/kaggle/working/work/testing/Pissarro/208257.jpg\n/kaggle/working/work/testing/Pissarro/208277.jpg\n/kaggle/working/work/testing/Pissarro/208275.jpg\n/kaggle/working/work/testing/Pissarro/208210.jpg\n/kaggle/working/work/testing/Pissarro/208496.jpg\n/kaggle/working/work/testing/Pissarro/208256.jpg\n/kaggle/working/work/testing/Pissarro/208076.jpg\n/kaggle/working/work/testing/Pissarro/208047.jpg\n/kaggle/working/work/testing/Gauguin/190597.jpg\n/kaggle/working/work/testing/Gauguin/190785.jpg\n/kaggle/working/work/testing/Gauguin/190566.jpg\n/kaggle/working/work/testing/Gauguin/190461.jpg\n/kaggle/working/work/testing/Gauguin/190603.jpg\n/kaggle/working/work/testing/Gauguin/190741.jpg\n/kaggle/working/work/testing/Gauguin/190537.jpg\n/kaggle/working/work/testing/Gauguin/190715.jpg\n/kaggle/working/work/testing/Gauguin/190821.jpg\n/kaggle/working/work/testing/Gauguin/190810.jpg\n/kaggle/working/work/testing/Gauguin/190682.jpg\n/kaggle/working/work/testing/Gauguin/190713.jpg\n/kaggle/working/work/testing/Gauguin/190464.jpg\n/kaggle/working/work/testing/Gauguin/190675.jpg\n/kaggle/working/work/testing/Gauguin/190812.jpg\n/kaggle/working/work/testing/Gauguin/190649.jpg\n/kaggle/working/work/testing/Gauguin/190581.jpg\n/kaggle/working/work/testing/Gauguin/190488.jpg\n/kaggle/working/work/testing/Gauguin/190751.jpg\n/kaggle/working/work/testing/Gauguin/190730.jpg\n/kaggle/working/work/testing/Gauguin/190800.jpg\n/kaggle/working/work/testing/Gauguin/190779.jpg\n/kaggle/working/work/testing/Gauguin/190624.jpg\n/kaggle/working/work/testing/Gauguin/190460.jpg\n/kaggle/working/work/testing/Gauguin/190494.jpg\n/kaggle/working/work/testing/Gauguin/190806.jpg\n/kaggle/working/work/testing/Gauguin/190489.jpg\n/kaggle/working/work/testing/Gauguin/190753.jpg\n/kaggle/working/work/testing/Gauguin/190738.jpg\n/kaggle/working/work/testing/Gauguin/190463.jpg\n/kaggle/working/work/testing/Gauguin/190663.jpg\n/kaggle/working/work/testing/Gauguin/190528.jpg\n/kaggle/working/work/testing/Gauguin/190757.jpg\n/kaggle/working/work/testing/Gauguin/190534.jpg\n/kaggle/working/work/testing/Gauguin/190570.jpg\n/kaggle/working/work/testing/Gauguin/190709.jpg\n/kaggle/working/work/testing/Gauguin/190454.jpg\n/kaggle/working/work/testing/Gauguin/190564.jpg\n/kaggle/working/work/testing/Gauguin/190606.jpg\n/kaggle/working/work/testing/Gauguin/190511.jpg\n/kaggle/working/work/testing/Gauguin/190590.jpg\n/kaggle/working/work/testing/Gauguin/190544.jpg\n/kaggle/working/work/testing/Gauguin/190773.jpg\n/kaggle/working/work/testing/Gauguin/190621.jpg\n/kaggle/working/work/testing/Gauguin/190467.jpg\n/kaggle/working/work/testing/Gauguin/190707.jpg\n/kaggle/working/work/testing/Gauguin/190588.jpg\n/kaggle/working/work/testing/Gauguin/190491.jpg\n/kaggle/working/work/testing/Gauguin/190832.jpg\n/kaggle/working/work/testing/Gauguin/190758.jpg\n/kaggle/working/work/testing/Gauguin/190557.jpg\n/kaggle/working/work/testing/Gauguin/190535.jpg\n/kaggle/working/work/testing/Gauguin/190486.jpg\n/kaggle/working/work/testing/Gauguin/190589.jpg\n/kaggle/working/work/testing/Gauguin/190653.jpg\n/kaggle/working/work/testing/Gauguin/190630.jpg\n/kaggle/working/work/testing/Gauguin/190809.jpg\n/kaggle/working/work/testing/Gauguin/190505.jpg\n/kaggle/working/work/testing/Gauguin/190823.jpg\n/kaggle/working/work/testing/Gauguin/190672.jpg\n/kaggle/working/work/testing/Gauguin/190759.jpg\n/kaggle/working/work/testing/Gauguin/190798.jpg\n/kaggle/working/work/testing/Gauguin/190766.jpg\n/kaggle/working/work/testing/Gauguin/190477.jpg\n/kaggle/working/work/testing/Gauguin/190563.jpg\n/kaggle/working/work/testing/Gauguin/190466.jpg\n/kaggle/working/work/testing/Gauguin/190768.jpg\n/kaggle/working/work/testing/Gauguin/190502.jpg\n/kaggle/working/work/testing/Gauguin/190825.jpg\n/kaggle/working/work/testing/Gauguin/190818.jpg\n/kaggle/working/work/testing/Gauguin/190471.jpg\n/kaggle/working/work/testing/Gauguin/190611.jpg\n/kaggle/working/work/testing/VanGogh/206747.jpg\n/kaggle/working/work/testing/VanGogh/206650.jpg\n/kaggle/working/work/testing/VanGogh/205762.jpg\n/kaggle/working/work/testing/VanGogh/206840.jpg\n/kaggle/working/work/testing/VanGogh/206927.jpg\n/kaggle/working/work/testing/VanGogh/206930.jpg\n/kaggle/working/work/testing/VanGogh/206204.jpg\n/kaggle/working/work/testing/VanGogh/206589.jpg\n/kaggle/working/work/testing/VanGogh/205950.jpg\n/kaggle/working/work/testing/VanGogh/206765.jpg\n/kaggle/working/work/testing/VanGogh/206824.jpg\n/kaggle/working/work/testing/VanGogh/205858.jpg\n/kaggle/working/work/testing/VanGogh/206665.jpg\n/kaggle/working/work/testing/VanGogh/206451.jpg\n/kaggle/working/work/testing/VanGogh/206772.jpg\n/kaggle/working/work/testing/VanGogh/206326.jpg\n/kaggle/working/work/testing/VanGogh/206842.jpg\n/kaggle/working/work/testing/VanGogh/206748.jpg\n/kaggle/working/work/testing/VanGogh/206935.jpg\n/kaggle/working/work/testing/VanGogh/206270.jpg\n/kaggle/working/work/testing/VanGogh/206398.jpg\n/kaggle/working/work/testing/VanGogh/205846.jpg\n/kaggle/working/work/testing/VanGogh/206260.jpg\n/kaggle/working/work/testing/VanGogh/206555.jpg\n/kaggle/working/work/testing/VanGogh/205994.jpg\n/kaggle/working/work/testing/VanGogh/206940.jpg\n/kaggle/working/work/testing/VanGogh/205754.jpg\n/kaggle/working/work/testing/VanGogh/206611.jpg\n/kaggle/working/work/testing/VanGogh/206354.jpg\n/kaggle/working/work/testing/VanGogh/206861.jpg\n/kaggle/working/work/testing/VanGogh/206287.jpg\n/kaggle/working/work/testing/VanGogh/205655.jpg\n/kaggle/working/work/testing/VanGogh/206807.jpg\n/kaggle/working/work/testing/VanGogh/206253.jpg\n/kaggle/working/work/testing/VanGogh/206322.jpg\n/kaggle/working/work/testing/VanGogh/206151.jpg\n/kaggle/working/work/testing/VanGogh/206900.jpg\n/kaggle/working/work/testing/VanGogh/206580.jpg\n/kaggle/working/work/testing/VanGogh/206282.jpg\n/kaggle/working/work/testing/VanGogh/206175.jpg\n/kaggle/working/work/testing/VanGogh/206554.jpg\n/kaggle/working/work/testing/VanGogh/206386.jpg\n/kaggle/working/work/testing/VanGogh/206027.jpg\n/kaggle/working/work/testing/VanGogh/206619.jpg\n/kaggle/working/work/testing/VanGogh/206523.jpg\n/kaggle/working/work/testing/VanGogh/206077.jpg\n/kaggle/working/work/testing/VanGogh/206289.jpg\n/kaggle/working/work/testing/VanGogh/206516.jpg\n/kaggle/working/work/testing/VanGogh/206177.jpg\n/kaggle/working/work/testing/VanGogh/206556.jpg\n/kaggle/working/work/testing/VanGogh/206146.jpg\n/kaggle/working/work/testing/VanGogh/206539.jpg\n/kaggle/working/work/testing/VanGogh/206760.jpg\n/kaggle/working/work/testing/VanGogh/205684.jpg\n/kaggle/working/work/testing/VanGogh/205688.jpg\n/kaggle/working/work/testing/VanGogh/206719.jpg\n/kaggle/working/work/testing/VanGogh/205968.jpg\n/kaggle/working/work/testing/VanGogh/206844.jpg\n/kaggle/working/work/testing/VanGogh/205918.jpg\n/kaggle/working/work/testing/VanGogh/205820.jpg\n/kaggle/working/work/testing/VanGogh/205881.jpg\n/kaggle/working/work/testing/VanGogh/206699.jpg\n/kaggle/working/work/testing/VanGogh/206449.jpg\n/kaggle/working/work/testing/VanGogh/205893.jpg\n/kaggle/working/work/testing/VanGogh/206478.jpg\n/kaggle/working/work/testing/VanGogh/206888.jpg\n/kaggle/working/work/testing/Matisse/214070.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820895.jpg\n/kaggle/working/work/testing/Matisse/214202.jpg\n/kaggle/working/work/testing/Matisse/214125.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820520.jpg\n/kaggle/working/work/testing/Matisse/214201.jpg\n/kaggle/working/work/testing/Matisse/214306.jpg\n/kaggle/working/work/testing/Matisse/214346.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820889.jpg\n/kaggle/working/work/testing/Matisse/214323.jpg\n/kaggle/working/work/testing/Matisse/214132.jpg\n/kaggle/working/work/testing/Matisse/213984.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820832.jpg\n/kaggle/working/work/testing/Matisse/214268.jpg\n/kaggle/working/work/testing/Matisse/213964.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820556.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820879.jpg\n/kaggle/working/work/testing/Matisse/214135.jpg\n/kaggle/working/work/testing/Matisse/213892.jpg\n/kaggle/working/work/testing/Matisse/213908.jpg\n/kaggle/working/work/testing/Matisse/214181.jpg\n/kaggle/working/work/testing/Matisse/214166.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820933.jpg\n/kaggle/working/work/testing/Matisse/213900.jpg\n/kaggle/working/work/testing/Matisse/214063.jpg\n/kaggle/working/work/testing/Matisse/214065.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820552.jpg\n/kaggle/working/work/testing/Matisse/214080.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820597.jpg\n/kaggle/working/work/testing/Matisse/291315.jpg\n/kaggle/working/work/testing/Matisse/214350.jpg\n/kaggle/working/work/testing/Matisse/214218.jpg\n/kaggle/working/work/testing/Matisse/214146.jpg\n/kaggle/working/work/testing/Matisse/213893.jpg\n/kaggle/working/work/testing/Matisse/214254.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820838.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820718.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820873.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820476.jpg\n/kaggle/working/work/testing/Matisse/213925.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820515.jpg\n/kaggle/working/work/testing/Matisse/214310.jpg\n/kaggle/working/work/testing/Matisse/214073.jpg\n/kaggle/working/work/testing/Matisse/214234.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820877.jpg\n/kaggle/working/work/testing/Matisse/214171.jpg\n/kaggle/working/work/testing/Matisse/214005.jpg\n/kaggle/working/work/testing/Matisse/214276.jpg\n/kaggle/working/work/testing/Matisse/214261.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820898.jpg\n/kaggle/working/work/testing/Matisse/214050.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820624.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820924.jpg\n/kaggle/working/work/testing/Matisse/214366.jpg\n/kaggle/working/work/testing/Matisse/214027.jpg\n/kaggle/working/work/testing/Matisse/214042.jpg\n/kaggle/working/work/testing/Matisse/214213.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820835.jpg\n/kaggle/working/work/testing/Matisse/213969.jpg\n/kaggle/working/work/testing/Matisse/214108.jpg\n/kaggle/working/work/testing/Matisse/214300.jpg\n/kaggle/working/work/testing/Matisse/214340.jpg\n/kaggle/working/work/testing/Matisse/213941.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820918.jpg\n/kaggle/working/work/testing/Matisse/214316.jpg\n/kaggle/working/work/testing/Matisse/214278.jpg\n/kaggle/working/work/testing/Matisse/214087.jpg\n/kaggle/working/work/testing/Matisse/213968.jpg\n/kaggle/working/work/testing/Matisse/214251.jpg\n/kaggle/working/work/testing/Matisse/214076.jpg\n/kaggle/working/work/testing/Matisse/214091.jpg\n/kaggle/working/work/testing/Matisse/9223372032559820876.jpg\n/kaggle/working/work/testing/Monet/211864.jpg\n/kaggle/working/work/testing/Monet/212723.jpg\n/kaggle/working/work/testing/Monet/212694.jpg\n/kaggle/working/work/testing/Monet/212076.jpg\n/kaggle/working/work/testing/Monet/212274.jpg\n/kaggle/working/work/testing/Monet/212426.jpg\n/kaggle/working/work/testing/Monet/212487.jpg\n/kaggle/working/work/testing/Monet/212734.jpg\n/kaggle/working/work/testing/Monet/212654.jpg\n/kaggle/working/work/testing/Monet/211989.jpg\n/kaggle/working/work/testing/Monet/211908.jpg\n/kaggle/working/work/testing/Monet/212583.jpg\n/kaggle/working/work/testing/Monet/212651.jpg\n/kaggle/working/work/testing/Monet/212022.jpg\n/kaggle/working/work/testing/Monet/212017.jpg\n/kaggle/working/work/testing/Monet/212563.jpg\n/kaggle/working/work/testing/Monet/212086.jpg\n/kaggle/working/work/testing/Monet/212457.jpg\n/kaggle/working/work/testing/Monet/212200.jpg\n/kaggle/working/work/testing/Monet/212174.jpg\n/kaggle/working/work/testing/Monet/212064.jpg\n/kaggle/working/work/testing/Monet/212538.jpg\n/kaggle/working/work/testing/Monet/212626.jpg\n/kaggle/working/work/testing/Monet/212222.jpg\n/kaggle/working/work/testing/Monet/212072.jpg\n/kaggle/working/work/testing/Monet/212039.jpg\n/kaggle/working/work/testing/Monet/212657.jpg\n/kaggle/working/work/testing/Monet/211972.jpg\n/kaggle/working/work/testing/Monet/212690.jpg\n/kaggle/working/work/testing/Monet/211821.jpg\n/kaggle/working/work/testing/Monet/211813.jpg\n/kaggle/working/work/testing/Monet/211743.jpg\n/kaggle/working/work/testing/Monet/212379.jpg\n/kaggle/working/work/testing/Monet/211740.jpg\n/kaggle/working/work/testing/Monet/212557.jpg\n/kaggle/working/work/testing/Monet/212054.jpg\n/kaggle/working/work/testing/Monet/212560.jpg\n/kaggle/working/work/testing/Monet/212299.jpg\n/kaggle/working/work/testing/Monet/212513.jpg\n/kaggle/working/work/testing/Monet/211842.jpg\n/kaggle/working/work/testing/Monet/212277.jpg\n/kaggle/working/work/testing/Monet/211926.jpg\n/kaggle/working/work/testing/Monet/212287.jpg\n/kaggle/working/work/testing/Monet/211893.jpg\n/kaggle/working/work/testing/Monet/211726.jpg\n/kaggle/working/work/testing/Monet/211711.jpg\n/kaggle/working/work/testing/Monet/212598.jpg\n/kaggle/working/work/testing/Monet/212568.jpg\n/kaggle/working/work/testing/Monet/211752.jpg\n/kaggle/working/work/testing/Monet/211967.jpg\n/kaggle/working/work/testing/Monet/212279.jpg\n/kaggle/working/work/testing/Monet/211935.jpg\n/kaggle/working/work/testing/Monet/212368.jpg\n/kaggle/working/work/testing/Monet/211764.jpg\n/kaggle/working/work/testing/Monet/211936.jpg\n/kaggle/working/work/testing/Monet/211880.jpg\n/kaggle/working/work/testing/Monet/212184.jpg\n/kaggle/working/work/testing/Monet/212471.jpg\n/kaggle/working/work/testing/Monet/212474.jpg\n/kaggle/working/work/testing/Monet/211805.jpg\n/kaggle/working/work/testing/Monet/211937.jpg\n/kaggle/working/work/testing/Monet/212322.jpg\n/kaggle/working/work/testing/Monet/212158.jpg\n/kaggle/working/work/testing/Monet/211788.jpg\n/kaggle/working/work/testing/Monet/211854.jpg\n/kaggle/working/work/testing/Monet/212103.jpg\n/kaggle/working/work/testing/Monet/212679.jpg\n/kaggle/working/work/testing/Monet/212427.jpg\n/kaggle/working/work/testing/Monet/212466.jpg\n/kaggle/working/work/testing/Monet/212638.jpg\n/kaggle/working/work/testing/Monet/212079.jpg\n/kaggle/working/work/testing/Monet/211810.jpg\n/kaggle/working/work/testing/Sargent/265901.jpg\n/kaggle/working/work/testing/Sargent/266106.jpg\n/kaggle/working/work/testing/Sargent/265834.jpg\n/kaggle/working/work/testing/Sargent/265854.jpg\n/kaggle/working/work/testing/Sargent/265724.jpg\n/kaggle/working/work/testing/Sargent/266230.jpg\n/kaggle/working/work/testing/Sargent/265843.jpg\n/kaggle/working/work/testing/Sargent/266139.jpg\n/kaggle/working/work/testing/Sargent/266098.jpg\n/kaggle/working/work/testing/Sargent/266046.jpg\n/kaggle/working/work/testing/Sargent/265733.jpg\n/kaggle/working/work/testing/Sargent/265764.jpg\n/kaggle/working/work/testing/Sargent/266178.jpg\n/kaggle/working/work/testing/Sargent/265936.jpg\n/kaggle/working/work/testing/Sargent/266174.jpg\n/kaggle/working/work/testing/Sargent/266112.jpg\n/kaggle/working/work/testing/Sargent/265820.jpg\n/kaggle/working/work/testing/Sargent/265675.jpg\n/kaggle/working/work/testing/Sargent/265806.jpg\n/kaggle/working/work/testing/Sargent/266148.jpg\n/kaggle/working/work/testing/Sargent/266145.jpg\n/kaggle/working/work/testing/Sargent/265875.jpg\n/kaggle/working/work/testing/Sargent/266004.jpg\n/kaggle/working/work/testing/Sargent/265709.jpg\n/kaggle/working/work/testing/Sargent/266158.jpg\n/kaggle/working/work/testing/Sargent/265853.jpg\n/kaggle/working/work/testing/Sargent/265734.jpg\n/kaggle/working/work/testing/Sargent/265711.jpg\n/kaggle/working/work/testing/Sargent/265752.jpg\n/kaggle/working/work/testing/Sargent/265965.jpg\n/kaggle/working/work/testing/Sargent/266122.jpg\n/kaggle/working/work/testing/Sargent/265971.jpg\n/kaggle/working/work/testing/Sargent/265654.jpg\n/kaggle/working/work/testing/Sargent/266159.jpg\n/kaggle/working/work/testing/Sargent/265696.jpg\n/kaggle/working/work/testing/Sargent/265917.jpg\n/kaggle/working/work/testing/Sargent/266138.jpg\n/kaggle/working/work/testing/Sargent/265882.jpg\n/kaggle/working/work/testing/Sargent/266060.jpg\n/kaggle/working/work/testing/Sargent/266172.jpg\n/kaggle/working/work/testing/Sargent/265701.jpg\n/kaggle/working/work/testing/Sargent/265998.jpg\n/kaggle/working/work/testing/Sargent/265747.jpg\n/kaggle/working/work/testing/Sargent/266235.jpg\n/kaggle/working/work/testing/Sargent/265658.jpg\n/kaggle/working/work/testing/Sargent/266219.jpg\n/kaggle/working/work/testing/Sargent/265673.jpg\n/kaggle/working/work/testing/Sargent/266063.jpg\n/kaggle/working/work/testing/Sargent/265937.jpg\n/kaggle/working/work/testing/Sargent/266125.jpg\n/kaggle/working/work/testing/Sargent/265870.jpg\n/kaggle/working/work/testing/Sargent/265805.jpg\n/kaggle/working/work/testing/Sargent/266203.jpg\n/kaggle/working/work/testing/Sargent/265964.jpg\n/kaggle/working/work/testing/Sargent/265990.jpg\n/kaggle/working/work/testing/Sargent/265898.jpg\n/kaggle/working/work/testing/Sargent/265688.jpg\n/kaggle/working/work/testing/Sargent/266195.jpg\n/kaggle/working/work/testing/Sargent/265809.jpg\n/kaggle/working/work/testing/Sargent/265725.jpg\n/kaggle/working/work/testing/Sargent/265798.jpg\n/kaggle/working/work/testing/Sargent/266025.jpg\n/kaggle/working/work/testing/Sargent/265968.jpg\n/kaggle/working/work/testing/Sargent/266204.jpg\n/kaggle/working/work/testing/Sargent/266241.jpg\n/kaggle/working/work/testing/Sargent/265650.jpg\n/kaggle/working/work/testing/Sargent/266094.jpg\n/kaggle/working/work/testing/Sargent/265797.jpg\n/kaggle/working/work/testing/Sargent/265865.jpg\n/kaggle/working/work/testing/Sargent/266049.jpg\n/kaggle/working/work/testing/Sargent/265657.jpg\n/kaggle/working/work/testing/Sargent/265888.jpg\n/kaggle/working/work/.git/packed-refs\n/kaggle/working/work/.git/HEAD\n/kaggle/working/work/.git/config\n/kaggle/working/work/.git/description\n/kaggle/working/work/.git/index\n/kaggle/working/work/.git/info/exclude\n/kaggle/working/work/.git/objects/pack/pack-c87964134e7809c72c123ee9e1c0006aebae5db3.pack\n/kaggle/working/work/.git/objects/pack/pack-c87964134e7809c72c123ee9e1c0006aebae5db3.idx\n/kaggle/working/work/.git/hooks/applypatch-msg.sample\n/kaggle/working/work/.git/hooks/pre-receive.sample\n/kaggle/working/work/.git/hooks/pre-rebase.sample\n/kaggle/working/work/.git/hooks/update.sample\n/kaggle/working/work/.git/hooks/pre-push.sample\n/kaggle/working/work/.git/hooks/pre-commit.sample\n/kaggle/working/work/.git/hooks/fsmonitor-watchman.sample\n/kaggle/working/work/.git/hooks/pre-applypatch.sample\n/kaggle/working/work/.git/hooks/commit-msg.sample\n/kaggle/working/work/.git/hooks/post-update.sample\n/kaggle/working/work/.git/hooks/prepare-commit-msg.sample\n/kaggle/working/work/.git/logs/HEAD\n/kaggle/working/work/.git/logs/refs/heads/master\n/kaggle/working/work/.git/logs/refs/remotes/origin/HEAD\n/kaggle/working/work/.git/refs/heads/master\n/kaggle/working/work/.git/refs/remotes/origin/HEAD\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport torch.utils.data as data\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nimport time, os, copy, argparse\nimport multiprocessing\n\nfrom matplotlib import pyplot as plt","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndef vgg_block_single(in_ch, out_ch, kernel_size=3, padding=1):\n    return nn.Sequential(\n        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2)\n        ) \n    \ndef vgg_block_double(in_ch, out_ch, kernel_size=3, padding=1):\n    return nn.Sequential(\n        nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding),\n        nn.ReLU(),\n        nn.Conv2d(out_ch, out_ch, kernel_size=kernel_size, padding=padding),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n\nclass MyVGG11(nn.Module):\n    def __init__(self, in_ch, num_classes):\n        super().__init__()\n\n        self.conv_block1 =vgg_block_single(in_ch,64)\n        self.conv_block2 =vgg_block_single(64,128)\n\n        self.conv_block3 =vgg_block_double(128,256)\n        self.conv_block4 =vgg_block_double(256,512)\n        self.conv_block5 =vgg_block_double(512,512)\n\n        self.fc_layers = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(),\n            nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        \n        x=self.conv_block1(x)\n        x=self.conv_block2(x)\n\n        x=self.conv_block3(x)\n        x=self.conv_block4(x)\n        x=self.conv_block5(x)\n\n        x=x.view(x.size(0), -1)\n\n        x=self.fc_layers(x)\n\n        return x","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_directory = '../input/impressionist-classifier-data/training/training'\nvalid_directory = '../input/impressionist-classifier-data/validation/validation'","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 64 \n# Number of epochs\nnum_epochs = 10\n# Number of classes\nnum_classes = 10","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\n\nimage_transforms = { \n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n}\n \n# Load data from folders\ndataset = {\n    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n}\n \n# Size of train and validation data\ndataset_sizes = {\n    'train':len(dataset['train']),\n    'valid':len(dataset['valid'])\n}\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create iterators for data loading\ndataloaders = {\n    'train':data.DataLoader(dataset['train'], batch_size=bs, shuffle=True, pin_memory=True, drop_last=True),\n    'valid':data.DataLoader(dataset['valid'], batch_size=bs, shuffle=True, pin_memory=True, drop_last=True)\n}\n\n# Class names or target labels\nclass_names = dataset['train'].classes\nprint(\"Classes:\", class_names)\n \n# Print the train and validation data sizes\nprint(\"Training-set size:\",dataset_sizes['train'],\n      \"\\nValidation-set size:\", dataset_sizes['valid'])\n\n# Set default device as gpu, if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","execution_count":10,"outputs":[{"output_type":"stream","text":"Classes: ['Cezanne', 'Degas', 'Gauguin', 'Hassam', 'Matisse', 'Monet', 'Pissarro', 'Renoir', 'Sargent', 'VanGogh']\nTraining-set size: 3988 \nValidation-set size: 990\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\n\n    # Modify fc layers to match num_classes\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs,num_classes )","execution_count":11,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ae475b77884b23a935f5faa2057f0b"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft = model_ft.to(device)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install torchsummary","execution_count":13,"outputs":[{"output_type":"stream","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nprint('Model Summary:-\\n')\nfor num, (name, param) in enumerate(model_ft.named_parameters()):\n    print(num, name, param.requires_grad )\nsummary(model_ft, input_size=(3, 224, 224))\nprint(model_ft)","execution_count":14,"outputs":[{"output_type":"stream","text":"Model Summary:-\n\n0 conv1.weight True\n1 bn1.weight True\n2 bn1.bias True\n3 layer1.0.conv1.weight True\n4 layer1.0.bn1.weight True\n5 layer1.0.bn1.bias True\n6 layer1.0.conv2.weight True\n7 layer1.0.bn2.weight True\n8 layer1.0.bn2.bias True\n9 layer1.1.conv1.weight True\n10 layer1.1.bn1.weight True\n11 layer1.1.bn1.bias True\n12 layer1.1.conv2.weight True\n13 layer1.1.bn2.weight True\n14 layer1.1.bn2.bias True\n15 layer2.0.conv1.weight True\n16 layer2.0.bn1.weight True\n17 layer2.0.bn1.bias True\n18 layer2.0.conv2.weight True\n19 layer2.0.bn2.weight True\n20 layer2.0.bn2.bias True\n21 layer2.0.downsample.0.weight True\n22 layer2.0.downsample.1.weight True\n23 layer2.0.downsample.1.bias True\n24 layer2.1.conv1.weight True\n25 layer2.1.bn1.weight True\n26 layer2.1.bn1.bias True\n27 layer2.1.conv2.weight True\n28 layer2.1.bn2.weight True\n29 layer2.1.bn2.bias True\n30 layer3.0.conv1.weight True\n31 layer3.0.bn1.weight True\n32 layer3.0.bn1.bias True\n33 layer3.0.conv2.weight True\n34 layer3.0.bn2.weight True\n35 layer3.0.bn2.bias True\n36 layer3.0.downsample.0.weight True\n37 layer3.0.downsample.1.weight True\n38 layer3.0.downsample.1.bias True\n39 layer3.1.conv1.weight True\n40 layer3.1.bn1.weight True\n41 layer3.1.bn1.bias True\n42 layer3.1.conv2.weight True\n43 layer3.1.bn2.weight True\n44 layer3.1.bn2.bias True\n45 layer4.0.conv1.weight True\n46 layer4.0.bn1.weight True\n47 layer4.0.bn1.bias True\n48 layer4.0.conv2.weight True\n49 layer4.0.bn2.weight True\n50 layer4.0.bn2.bias True\n51 layer4.0.downsample.0.weight True\n52 layer4.0.downsample.1.weight True\n53 layer4.0.downsample.1.bias True\n54 layer4.1.conv1.weight True\n55 layer4.1.bn1.weight True\n56 layer4.1.bn1.bias True\n57 layer4.1.conv2.weight True\n58 layer4.1.bn2.weight True\n59 layer4.1.bn2.bias True\n60 fc.weight True\n61 fc.bias True\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n              ReLU-3         [-1, 64, 112, 112]               0\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-6           [-1, 64, 56, 56]             128\n              ReLU-7           [-1, 64, 56, 56]               0\n            Conv2d-8           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-9           [-1, 64, 56, 56]             128\n             ReLU-10           [-1, 64, 56, 56]               0\n       BasicBlock-11           [-1, 64, 56, 56]               0\n           Conv2d-12           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-13           [-1, 64, 56, 56]             128\n             ReLU-14           [-1, 64, 56, 56]               0\n           Conv2d-15           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-16           [-1, 64, 56, 56]             128\n             ReLU-17           [-1, 64, 56, 56]               0\n       BasicBlock-18           [-1, 64, 56, 56]               0\n           Conv2d-19          [-1, 128, 28, 28]          73,728\n      BatchNorm2d-20          [-1, 128, 28, 28]             256\n             ReLU-21          [-1, 128, 28, 28]               0\n           Conv2d-22          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-23          [-1, 128, 28, 28]             256\n           Conv2d-24          [-1, 128, 28, 28]           8,192\n      BatchNorm2d-25          [-1, 128, 28, 28]             256\n             ReLU-26          [-1, 128, 28, 28]               0\n       BasicBlock-27          [-1, 128, 28, 28]               0\n           Conv2d-28          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-29          [-1, 128, 28, 28]             256\n             ReLU-30          [-1, 128, 28, 28]               0\n           Conv2d-31          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-32          [-1, 128, 28, 28]             256\n             ReLU-33          [-1, 128, 28, 28]               0\n       BasicBlock-34          [-1, 128, 28, 28]               0\n           Conv2d-35          [-1, 256, 14, 14]         294,912\n      BatchNorm2d-36          [-1, 256, 14, 14]             512\n             ReLU-37          [-1, 256, 14, 14]               0\n           Conv2d-38          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-39          [-1, 256, 14, 14]             512\n           Conv2d-40          [-1, 256, 14, 14]          32,768\n      BatchNorm2d-41          [-1, 256, 14, 14]             512\n             ReLU-42          [-1, 256, 14, 14]               0\n       BasicBlock-43          [-1, 256, 14, 14]               0\n           Conv2d-44          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-45          [-1, 256, 14, 14]             512\n             ReLU-46          [-1, 256, 14, 14]               0\n           Conv2d-47          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-48          [-1, 256, 14, 14]             512\n             ReLU-49          [-1, 256, 14, 14]               0\n       BasicBlock-50          [-1, 256, 14, 14]               0\n           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n             ReLU-53            [-1, 512, 7, 7]               0\n           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n           Conv2d-56            [-1, 512, 7, 7]         131,072\n      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n             ReLU-58            [-1, 512, 7, 7]               0\n       BasicBlock-59            [-1, 512, 7, 7]               0\n           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n             ReLU-62            [-1, 512, 7, 7]               0\n           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n             ReLU-65            [-1, 512, 7, 7]               0\n       BasicBlock-66            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n           Linear-68                   [-1, 10]           5,130\n================================================================\nTotal params: 11,181,642\nTrainable params: 11,181,642\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 62.79\nParams size (MB): 42.65\nEstimated Total Size (MB): 106.01\n----------------------------------------------------------------\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer \noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Learning rate decay\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\n# Model training routine \nprint(\"\\nTraining:-\\n\")\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=30):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    # Tensorboard summary\n    writer = SummaryWriter()\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device, non_blocking=True)\n                labels = labels.to(device, non_blocking=True)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # Record training loss and accuracy for each phase\n            if phase == 'train':\n                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n                writer.flush()\n            else:\n                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n                writer.flush()\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n","execution_count":15,"outputs":[{"output_type":"stream","text":"\nTraining:-\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=num_epochs)","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 0/9\n----------\ntrain Loss: 0.3985 Acc: 0.8724\nvalid Loss: 0.6397 Acc: 0.7596\n\nEpoch 1/9\n----------\ntrain Loss: 0.3991 Acc: 0.8694\nvalid Loss: 0.6312 Acc: 0.7687\n\nEpoch 2/9\n----------\ntrain Loss: 0.3905 Acc: 0.8786\nvalid Loss: 0.6356 Acc: 0.7636\n\nEpoch 3/9\n----------\ntrain Loss: 0.3805 Acc: 0.8837\nvalid Loss: 0.6278 Acc: 0.7758\n\nEpoch 4/9\n----------\ntrain Loss: 0.3889 Acc: 0.8811\nvalid Loss: 0.6221 Acc: 0.7788\n\nEpoch 5/9\n----------\ntrain Loss: 0.3669 Acc: 0.8862\nvalid Loss: 0.6287 Acc: 0.7727\n\nEpoch 6/9\n----------\ntrain Loss: 0.3772 Acc: 0.8776\nvalid Loss: 0.6238 Acc: 0.7768\n\nEpoch 7/9\n----------\ntrain Loss: 0.3804 Acc: 0.8811\nvalid Loss: 0.6272 Acc: 0.7687\n\nEpoch 8/9\n----------\ntrain Loss: 0.3697 Acc: 0.8837\nvalid Loss: 0.6375 Acc: 0.7687\n\nEpoch 9/9\n----------\ntrain Loss: 0.3792 Acc: 0.8791\nvalid Loss: 0.6374 Acc: 0.7667\n\nTraining complete in 30m 44s\nBest val Acc: 0.778788\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH=\"model_1.pth\" \nprint(\"\\nSaving the model...\")\ntorch.save(model_ft, PATH)","execution_count":20,"outputs":[{"output_type":"stream","text":"\nSaving the model...\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport torch.utils.data as data\nimport multiprocessing\nfrom sklearn.metrics import confusion_matrix","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/abhisingh007224/work.git","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'work'...\nremote: Enumerating objects: 775, done.\u001b[K\nremote: Counting objects: 100% (775/775), done.\u001b[K\nremote: Compressing objects: 100% (772/772), done.\u001b[K\nremote: Total 775 (delta 22), reused 730 (delta 2), pack-reused 0\u001b[K\nReceiving objects: 100% (775/775), 311.52 MiB | 43.35 MiB/s, done.\nResolving deltas: 100% (22/22), done.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/abhisingh007224/model.git","execution_count":28,"outputs":[{"output_type":"stream","text":"Cloning into 'model'...\nremote: Enumerating objects: 5, done.\u001b[K\nremote: Counting objects: 100% (5/5), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (5/5), done.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"EVAL_MODEL='/kaggle/working/model/model/model_1.pth'\nmodel = torch.load(EVAL_MODEL)\nmodel.eval()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./model_1.pth')","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"/kaggle/working/model_1.pth","text/html":"<a href='./model_1.pth' target='_blank'>./model_1.pth</a><br>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbs = 8\n\nEVAL_DIR='/kaggle/working/work/testing/'\n\n\n# Prepare the eval data loader\neval_transform=transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])])\n\neval_dataset=datasets.ImageFolder(root=EVAL_DIR, transform=eval_transform)\neval_loader=data.DataLoader(eval_dataset, batch_size=bs, shuffle=True, pin_memory=True)\n\n# Enable gpu mode, if cuda available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Number of classes and dataset-size\nnum_classes=len(eval_dataset.classes)\ndsize=len(eval_dataset)\n\n# Class label names\nclass_names=['Cezanne', 'Degas', 'Gauguin', 'Hassam', 'Matisse', 'Monet', 'Pissarro', 'Renoir', 'Sargent', 'VanGogh']\n\n# Initialize the prediction and label lists\npredlist=torch.zeros(0,dtype=torch.long, device='cpu')\nlbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n\n# Evaluate the model accuracy on the dataset\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in eval_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        predlist=torch.cat([predlist,predicted.view(-1).cpu()])\n        lbllist=torch.cat([lbllist,labels.view(-1).cpu()])\n\n# Overall accuracy\noverall_accuracy=100 * correct / total\nprint('Accuracy of the network on the {:d} test images: {:.2f}%'.format(dsize, \n    overall_accuracy))\n\n# Confusion matrix\nconf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\nprint('Confusion Matrix')\nprint('-'*16)\nprint(conf_mat,'\\n')\n\n","execution_count":31,"outputs":[{"output_type":"stream","text":"Accuracy of the network on the 714 test images: 80.11%\nConfusion Matrix\n----------------\n[[54  1  4  0  4  1  3  0  4  1]\n [ 0 57  3  0  1  0  1  1  6  3]\n [ 3  0 59  0  2  1  2  3  0  2]\n [ 1  0  2 55  1  4  4  2  2  1]\n [ 1  1  6  1 57  1  1  2  1  1]\n [ 0  0  0  7  2 50  7  1  2  3]\n [ 1  0  5  1  0  3 57  3  1  1]\n [ 0  0  3  0  0  2  0 66  1  0]\n [ 0  0  0  1  2  1  2  0 62  4]\n [ 0  1  3  1  4  0  1  0  1 55]] \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}